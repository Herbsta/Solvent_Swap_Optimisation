{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import os\n",
    "import glob\n",
    "import scipy.stats as stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = sqlite3.connect('../../db/MasterDatabase.db')\n",
    "# Execute the query and load the data into a pandas DataFrame\n",
    "df = pd.read_sql_query(\"SELECT * FROM selected_solubility_data\", connection)\n",
    "\n",
    "display(df)\n",
    "\n",
    "# Close the database connection\n",
    "connection.close()\n",
    "\n",
    "\n",
    "groups = [group.reset_index(drop=True) for _, group in df.groupby(['solvent_1', 'solvent_2', 'compound_id','temperature'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing for JA to conclude average MAPE scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of rows in each group\n",
    "group_sizes = [len(group) for group in groups]\n",
    "\n",
    "print(group_sizes)\n",
    "\n",
    "# Create a histogram of group sizes\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(group_sizes, bins=12, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "\n",
    "# Customize the plot\n",
    "plt.xlabel('Number of Data Points in Group')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Group Sizes in Dataset')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the results for:\n",
    "- 4 data points\n",
    "- 5 data points\n",
    "- 6 data points\n",
    "\n",
    "Apply a paired t test to test for statistical differences between the MAPE values of the models\n",
    "\n",
    "Get multiple samples under different random seeds for:\n",
    "- 4 data points\n",
    "- 5 data points\n",
    "- 6 data points\n",
    "\n",
    "Apply a paired t test to test for  statistical differences between the MAPE values within each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JAModelEmpirical:\n",
    "    groups = groups\n",
    "    \n",
    "    def __init__(self,x,random_seed=42):\n",
    "        self.results_df = None\n",
    "        self.random_seed = random_seed\n",
    "        self.x = x\n",
    "        \n",
    "    def __repr__(self):\n",
    "        if self.results_df is None:\n",
    "            return f\"JAModelEmpirical(x={self.x}, random_seed={self.random_seed})\"\n",
    "        else:\n",
    "            return f\"JAModelEmpirical(x={self.x}, random_seed={self.random_seed}, median mape={self.results_df['mape'].median():.4f})\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def load_from_csvs():\n",
    "        loaded = []\n",
    "\n",
    "        # Get all CSV files that match the pattern for curve fit results\n",
    "        csv_files = glob.glob('curve_fit_results_x_is_*_random_seed_is_*.csv')\n",
    "\n",
    "        # Load each file into a dictionary with keys indicating parameters\n",
    "        for file in csv_files:\n",
    "            # Extract x and random_seed from filename\n",
    "            filename = os.path.basename(file)\n",
    "            parts = filename.replace('curve_fit_results_x_is_', '').replace('.csv', '').split('_random_seed_is_')\n",
    "            \n",
    "            if len(parts) == 2:\n",
    "                x_value, random_seed = parts                \n",
    "                # Load the CSV file into a dataframe\n",
    "                df = pd.read_csv(file)\n",
    "                \n",
    "                new_model = JAModelEmpirical(x_value,random_seed)\n",
    "                new_model.results_df = df\n",
    "                loaded.append(new_model)\n",
    "        return loaded\n",
    "    \n",
    "    def desc_by_mape(self):\n",
    "        if self.results_df is None:\n",
    "            raise ValueError(\"No results available. Please run the curve_fitter method first.\")\n",
    "        \n",
    "        sorted_results = self.results_df.sort_values(by='mape', ascending=False)\n",
    "        return sorted_results.reset_index(drop=True)\n",
    "        \n",
    "    \n",
    "    def results_describe(self):\n",
    "        if self.results_df is None:\n",
    "            raise ValueError(\"No results available. Please run the curve_fitter method first.\")\n",
    "        \n",
    "        # Calculate average MAPE and other statistics\n",
    "        average_mape = self.results_df['mape'].mean()\n",
    "        median_mape = self.results_df['mape'].median()\n",
    "        min_mape = self.results_df['mape'].min()\n",
    "        max_mape = self.results_df['mape'].max()\n",
    "\n",
    "        print(f\"Average MAPE: {average_mape}\")\n",
    "        print(f\"Median MAPE: {median_mape}\")\n",
    "        print(f\"Min MAPE: {min_mape}\")\n",
    "        print(f\"Max MAPE: {max_mape}\")\n",
    "\n",
    "        # Print descriptive statistics for MAPE values\n",
    "        print(\"\\n--- MAPE Distribution Analysis ---\")\n",
    "        print(f\"Count of values: {len(self.results_df['mape'])}\")\n",
    "        print(f\"Number of values above 100%: {sum(self.results_df['mape'] > 100)}\")\n",
    "        print(f\"Number of values above 50%: {sum(self.results_df['mape'] > 50)}\")\n",
    "        print(f\"Number of values below 10%: {sum(self.results_df['mape'] < 10)}\")\n",
    "        print(f\"Number of values below 5%: {sum(self.results_df['mape'] < 5)}\")\n",
    "\n",
    "\n",
    "        # Return the full dataframe\n",
    "        display(self.results_df)\n",
    "    \n",
    "    def curve_fitter(self):\n",
    "        '''\n",
    "        where x is the number of random points to select from each group, excluding the first and last points.\n",
    "        The first and last points are always included in the fitting.\n",
    "        '''\n",
    "        random.seed(self.random_seed)  # Set the random seed for reproducibility\n",
    "        results = []\n",
    "        failed_groups = []\n",
    "        skipped_groups = []\n",
    "\n",
    "        for gn in tqdm(range(len(self.groups)), desc=\"Processing groups\"):\n",
    "            chosen_df = self.groups[gn]\n",
    "                \n",
    "            n = len(chosen_df)\n",
    "            if n < self.x+2:  # Skip groups that don't have enough points\n",
    "                print(f\"Skipping group {gn} due to insufficient data points\")\n",
    "                skipped_groups.append(gn)\n",
    "                continue\n",
    "                \n",
    "            random_indices = random.sample(range(1, n-1), self.x)\n",
    "            \n",
    "            solvent_2_pure = chosen_df[chosen_df['solvent_1_weight_fraction'] <= 0.01].iloc[0]['solubility_g_g']\n",
    "            solvent_1_pure = chosen_df[chosen_df['solvent_1_weight_fraction'] >= 0.99].iloc[0]['solubility_g_g']\n",
    "            specific_temperature = chosen_df['temperature'].iloc[0]\n",
    "            \n",
    "            # Create the random dataframe with x rows\n",
    "            fitting_df = chosen_df.iloc[[0] + random_indices + [n-1]].reset_index(drop=True)\n",
    "            \n",
    "            def jouyban_acree(f1, J0, J1, J2):   \n",
    "                # Calculate fraction of second solvent\n",
    "                f2 = 1 - f1\n",
    "                \n",
    "                # Modified interaction term that reduces likelihood of bimodal behavior\n",
    "                interaction_term = J0 * f1 * f2 + J1 * f1 * f2 * (2*f1 - 1) + J2 * f1 * f2 * (2*f1 - 1)**2\n",
    "                \n",
    "                # Calculate logarithm of solubility in the mixture\n",
    "                log_Cm = f1 * np.log(solvent_1_pure) + f2 * np.log(solvent_2_pure) + \\\n",
    "                        interaction_term / specific_temperature\n",
    "                \n",
    "                # Return the solubility in the mixture\n",
    "                return np.exp(log_Cm)\n",
    "            \n",
    "\n",
    "            # Suppress warnings during curve fitting\n",
    "            try:\n",
    "                with warnings.catch_warnings():\n",
    "                    warnings.simplefilter(\"ignore\")\n",
    "                    popt, pcov = curve_fit(jouyban_acree, fitting_df['solvent_1_weight_fraction'], fitting_df['solubility_g_g'])\n",
    "            except RuntimeError as e:\n",
    "                print(f\"RuntimeError: {e}\")\n",
    "                failed_groups.append(gn)\n",
    "                continue\n",
    "            \n",
    "            if (pcov is None or np.isnan(pcov).any() or np.isinf(pcov).any()):\n",
    "                print(f\"Failed to fit group {gn} due to covariance issues\")\n",
    "                failed_groups.append(gn)\n",
    "                continue\n",
    "            \n",
    "            # Extract the fitted parameters\n",
    "            J0, J1, J2 = popt\n",
    "            \n",
    "            # Calculate predicted solubility for all experimental data points\n",
    "            predicted_solubility = jouyban_acree(chosen_df['solvent_1_weight_fraction'], J0, J1, J2)\n",
    "            \n",
    "            # Root Mean Square Error\n",
    "            rmse = np.sqrt(mean_squared_error(chosen_df['solubility_g_g'], predicted_solubility))\n",
    "            \n",
    "            # R² score (coefficient of determination)\n",
    "            r2 = r2_score(chosen_df['solubility_g_g'], predicted_solubility)\n",
    "            \n",
    "            # Mean Absolute Percentage Error (MAPE)\n",
    "            mape = np.mean(np.abs((chosen_df['solubility_g_g'] - predicted_solubility) / chosen_df['solubility_g_g'])) * 100\n",
    "            \n",
    "            # Store results in dictionary\n",
    "            result = {\n",
    "                'group_index': gn,\n",
    "                'solvent_1': chosen_df['solvent_1'].iloc[0],\n",
    "                'solvent_2': chosen_df['solvent_2'].iloc[0],\n",
    "                'compound_id': chosen_df['compound_id'].iloc[0],\n",
    "                'temperature': specific_temperature,\n",
    "                'J0': J0,\n",
    "                'J1': J1,\n",
    "                'J2': J2,\n",
    "                'solvent_1_pure': solvent_1_pure,\n",
    "                'solvent_2_pure': solvent_2_pure,\n",
    "                'rmse': rmse,\n",
    "                'r2': r2,\n",
    "                'mape': mape,\n",
    "                'logmape': np.log10(mape) if mape > 0 else np.inf,\n",
    "            }\n",
    "            results.append(result)  \n",
    "        \n",
    "        self.results_df = pd.DataFrame(results)\n",
    "    \n",
    "    def save_results(self):\n",
    "        if self.results_df is None:\n",
    "            raise ValueError(\"No results available. Please run the curve_fitter method first.\")\n",
    "        \n",
    "        self.results_df.to_csv(f'curve_fit_results_x_is_{self.x}_random_seed_is_{self.random_seed}.csv', index=False)\n",
    "        print(f\"curve_fit_results_x_is_{self.x}_random_seed_is_{self.random_seed}.csv\")\n",
    "        \n",
    "    def plot_log_mape(self):\n",
    "        if self.results_df is None:\n",
    "            raise ValueError(\"No results available. Please run the curve_fitter method first.\")\n",
    "        \n",
    "        # Apply log transformation to the MAPE values\n",
    "        self.results_df['log_mape'] = np.log10(self.results_df['mape'])\n",
    "\n",
    "        # Create histogram\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.hist(self.results_df['log_mape'], bins=50, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "        plt.xlabel('log10(MAPE)')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.title('Histogram of log10(MAPE) Values')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "\n",
    "        # Add vertical lines for reference points\n",
    "        plt.axvline(x=np.log10(1), color='green', linestyle='--', label='MAPE = 1%')\n",
    "        plt.axvline(x=np.log10(10), color='orange', linestyle='--', label='MAPE = 10%')\n",
    "        plt.axvline(x=np.log10(100), color='red', linestyle='--', label='MAPE = 100%')\n",
    "\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # Print some statistics about the log-transformed MAPE\n",
    "        print(f\"Log10(MAPE) statistics:\")\n",
    "        print(f\"Mean: {np.mean(self.results_df['log_mape']):.4f}\")\n",
    "        print(f\"Median: {np.median(self.results_df['log_mape']):.4f}\")\n",
    "        print(f\"Min: {np.min(self.results_df['log_mape']):.4f}\")\n",
    "        print(f\"Max: {np.max(self.results_df['log_mape']):.4f}\")\n",
    "    \n",
    "    def plot(self,n):\n",
    "        if self.results_df is None:\n",
    "            raise ValueError(\"No results available. Please run the curve_fitter method first.\")\n",
    "        \n",
    "        selected = groups[self.results_df['group_index'].iloc[n]]\n",
    "        J0 = self.results_df['J0'].iloc[n]\n",
    "        J1 = self.results_df['J1'].iloc[n]\n",
    "        J2 = self.results_df['J2'].iloc[n]\n",
    "        solvent_1_pure = self.results_df['solvent_1_pure'].iloc[n]\n",
    "        solvent_2_pure = self.results_df['solvent_2_pure'].iloc[n]\n",
    "        specific_temperature = self.results_df['temperature'].iloc[n]\n",
    "\n",
    "        def jouyban_acree(f1, J0, J1, J2):   \n",
    "            # Calculate fraction of second solvent\n",
    "            f2 = 1 - f1\n",
    "            \n",
    "            # Modified interaction term that reduces likelihood of bimodal behavior\n",
    "            interaction_term = J0 * f1 * f2 + J1 * f1 * f2 * (2*f1 - 1) + J2 * f1 * f2 * (2*f1 - 1)**2\n",
    "            \n",
    "            # Calculate logarithm of solubility in the mixture\n",
    "            log_Cm = f1 * np.log(solvent_1_pure) + f2 * np.log(solvent_2_pure) + \\\n",
    "                        interaction_term / specific_temperature\n",
    "            \n",
    "            # Return the solubility in the mixture\n",
    "            return np.exp(log_Cm)\n",
    "            \n",
    "        x_values = np.linspace(0, 1, 101)\n",
    "\n",
    "        jouyban_acree_fit_values = jouyban_acree(x_values, J0, J1, J2)\n",
    "\n",
    "        # Plot the JA model\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(x_values, jouyban_acree_fit_values, label='Jouyban-Acree Model', color='blue')\n",
    "\n",
    "        # Add the experimental data points to the plot\n",
    "        plt.scatter(selected['solvent_1_weight_fraction'], selected['solubility_g_g'], color='red', label='Experimental Data', zorder=5)\n",
    "        plt.xlabel('Solvent 1 Weight Fraction')\n",
    "        plt.ylabel('Solubility (g/g)')\n",
    "        plt.title('Solubility vs Solvent 1 Weight Fraction (JA Model)')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "    \n",
    "    def paired_t_test(self, other_model):\n",
    "        if self.results_df is None or other_model.results_df is None:\n",
    "            raise ValueError(\"Both models must have results to perform the paired t-test.\")\n",
    "        \n",
    "        # Merge the two dataframes on the group index\n",
    "        merged_df = pd.merge(self.results_df, other_model.results_df, on='group_index', suffixes=('_model1', '_model2'))\n",
    "        \n",
    "        # Perform paired t-test on MAPE values\n",
    "        t_statistic, p_value = stats.ttest_rel(merged_df['logmape_model1'], merged_df['logmape_model2'])\n",
    "        \n",
    "        print(\"\\nPaired t-test results:\")\n",
    "        print(f\"t-statistic: {t_statistic:.4f}\")\n",
    "        print(f\"p-value: {p_value:.4f}\")\n",
    "        \n",
    "        if p_value < 0.05:\n",
    "            print(\"There is a statistically significant difference between the logmape values (p < 0.05)\")\n",
    "        else:\n",
    "            print(\"There is no statistically significant difference between the logmape values (p >= 0.05)\")\n",
    "\n",
    "        # Visualize the differences\n",
    "        plt.figure(figsize=(8, 4))\n",
    "\n",
    "        # Histogram of differences\n",
    "        plt.subplot(1, 2, 1)\n",
    "        \n",
    "        merged_df['diff'] = merged_df['logmape_model1'] - merged_df['logmape_model2']\n",
    "        \n",
    "        \n",
    "        plt.hist(merged_df['diff'], bins=30, color='skyblue', edgecolor='black')\n",
    "        plt.axvline(x=0, color='red', linestyle='--')\n",
    "        plt.xlabel('Difference in logmape')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.title('Histogram of Differences')\n",
    "\n",
    "        # Scatter plot comparing the two sets\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.scatter(merged_df['logmape_model1'], merged_df['logmape_model2'], alpha=0.5)\n",
    "        plt.plot([-15, 5], [-15, 5], 'r--')  # Line y=x for reference\n",
    "        plt.xlabel(f'{self}')\n",
    "        plt.ylabel(f'{other_model}')\n",
    "        plt.title('Comparison of logmape Values')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        \n",
    "        return t_statistic, p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_range = range(3,7)\n",
    "random_range = range(42,46)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in x_range:\n",
    "    for random_seed in random_range:\n",
    "        model = JAModelEmpirical(x,random_seed)\n",
    "        model.curve_fitter()\n",
    "        model.save_results()\n",
    "        model.plot_log_mape()\n",
    "        model.results_describe()\n",
    "        \n",
    "        # Save the model to a file\n",
    "        with open(f'model_x_{x}_random_seed_{random_seed}.pkl', 'wb') as f:\n",
    "            pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JAModel = JAModelEmpirical(x=4, random_seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JAModel.curve_fitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JAModel.save_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JAModel.plot(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = JAModelEmpirical.load_from_csvs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models[0].paired_t_test(models[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
