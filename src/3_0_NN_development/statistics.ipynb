{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mainv3 import SystemDesign\n",
    "import matplotlib.pyplot as plt\n",
    "from equations import JouybanAcreeModel\n",
    "import numpy as np\n",
    "from groups import ja_groups\n",
    "import glob\n",
    "from data_module import DataProcessor\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from equations import JouybanAcreeModel\n",
    "from groups import ja_groups\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "# Set up initial configurations for plots\n",
    "plt.rcParams.update({\n",
    "    'font.size': 12,          # Default font size\n",
    "    'axes.labelsize': 14,     # Axis labels\n",
    "    'axes.titlesize': 16,     # Subplot titles\n",
    "    'xtick.labelsize': 12,    # X-axis tick labels\n",
    "    'ytick.labelsize': 12,    # Y-axis tick labels\n",
    "    'legend.fontsize': 12,    # Legend text\n",
    "    'figure.titlesize': 18    # Figure title\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ja_model = JouybanAcreeModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(weight_fractions: pd.Series, solubility_g_g: pd.Series, solvent_1_pure, solvent_2_pure, temperature, J0, J1, J2):\n",
    "    predicted_solubility = ja_model.predict(\n",
    "        weight_fractions,\n",
    "        solvent_1_pure,\n",
    "        solvent_2_pure,\n",
    "        temperature,\n",
    "        J0, J1, J2\n",
    "    )\n",
    "\n",
    "    # Calculate error metrics\n",
    "    rmse = np.sqrt(mean_squared_error(weight_fractions, predicted_solubility))\n",
    "    r2 = r2_score(solubility_g_g, predicted_solubility)\n",
    "    mape = np.mean(np.abs((solubility_g_g - predicted_solubility) / solubility_g_g)) * 100\n",
    "    \n",
    "    return rmse, r2, mape\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def paired_t_test(results_df, other_model_results_df):\n",
    "   \n",
    "    # Merge the two dataframes on the group index\n",
    "    merged_df = pd.merge(results_df, other_model_results_df, \n",
    "                            on='group_index', suffixes=('_model1', '_model2'), how='inner')\n",
    "    \n",
    "    # Perform paired t-test on logmape values\n",
    "    t_statistic, p_value = stats.ttest_rel(merged_df['logmape_model1'], \n",
    "                                            merged_df['logmape_model2'], \n",
    "                                            alternative='less')\n",
    "    \n",
    "    print(\"\\nPaired t-test results:\")\n",
    "    print(f\"t-statistic: {t_statistic:.4f}\")\n",
    "    print(f\"p-value: {p_value:.4f}\")\n",
    "    \n",
    "    if p_value < 0.025:\n",
    "        print(f\"There is a statistically significant difference with model 1 having lower logmape values (p < {0.025}).\")\n",
    "    else:\n",
    "        print(f\"There is no statistically significant evidence that model 1 has lower logmape values (p >= {0.025}).\")\n",
    "\n",
    "    diff_mean = merged_df['logmape_model1'].mean() - merged_df['logmape_model2'].mean()\n",
    "    num_better = sum(merged_df['logmape_model1'] < merged_df['logmape_model2'])\n",
    "    total_cases = len(merged_df)\n",
    "    percentage_better = (num_better / total_cases) * 100\n",
    "    \n",
    "    print(f\"\\nAdditional statistics:\")\n",
    "    print(f\"Mean difference in logmape: {diff_mean:.4f}\")\n",
    "    print(f\"Cases where model 1 performs better: {num_better} out of {total_cases} ({percentage_better:.1f}%)\")\n",
    "\n",
    "\n",
    "    return t_statistic, p_value, merged_df['mape_model1'] - merged_df['mape_model2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Comparison(system_load: SystemDesign):\n",
    "    x,y = system_load.get_data_split_df()\n",
    "    y_pred = system_load.predict_model(x)\n",
    "\n",
    "    df = system_load.dataprocess.raw_data.merge(\n",
    "        y_pred,\n",
    "        left_index=True,\n",
    "        right_index=True,\n",
    "        suffixes=('','_pred')\n",
    "    )\n",
    "    \n",
    "    results = []\n",
    "    for i,row in df.iterrows():\n",
    "        gn = int(row['group_index'])\n",
    "        \n",
    "        group = ja_groups[gn]\n",
    "        CalculateMetrics = calculate_metrics(\n",
    "            group['solvent_1_weight_fraction'],\n",
    "            group['solubility_g_g'],\n",
    "            row['solvent_1_pure'],\n",
    "            row['solvent_2_pure'],\n",
    "            row['temperature'],\n",
    "            row['J0_pred'],\n",
    "            row['J1_pred'],\n",
    "            row['J2_pred']\n",
    "        )\n",
    "        \n",
    "        results.append({\n",
    "            \"group_index\": gn,\n",
    "            \"rmse\": CalculateMetrics[0],\n",
    "            \"r2\": CalculateMetrics[1],\n",
    "            \"mape\": CalculateMetrics[2],\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dir = '../../output/models'\n",
    "model_files = glob.glob(f'{models_dir}/*.pkl')\n",
    "\n",
    "results = {}\n",
    "for model_file in model_files:\n",
    "    system: SystemDesign = SystemDesign.load(model_file)\n",
    "    # Extract model name from file path\n",
    "    model_name = model_file.split('\\\\')[-1].replace('.pkl', '')\n",
    "\n",
    "    # Get comparison results for this model\n",
    "    comparison_df = Comparison(system)\n",
    "    mae_J0, mae_J1, mae_J2 = system.get_predictions_and_metrics()\n",
    "\n",
    "    # Store results in dictionary with model name as key\n",
    "    results[model_name] = {\n",
    "        'comparison': comparison_df,\n",
    "        'mae_J0': mae_J0,  # Will be updated after metrics calculation\n",
    "        'mae_J1': mae_J1,\n",
    "        'mae_J2': mae_J2,\n",
    "        'system': system\n",
    "    }\n",
    "    \n",
    "    display(comparison_df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_df = []\n",
    "\n",
    "for key, value in results.items():\n",
    "    log_mape = float(np.log(value['comparison']['mape']).mean())\n",
    "    \n",
    "    comparison_df.append({\n",
    "        'model_name': key,\n",
    "        'logmape': log_mape,\n",
    "        'rmse': value['comparison']['rmse'].mean(),\n",
    "        'r2': value['comparison']['r2'].mean(),\n",
    "        'mape': value['comparison']['mape'].mean(),\n",
    "    })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_df).sort_values(by='logmape', ascending=True).reset_index(drop=True)\n",
    "# Extract components from model_name by splitting on underscore\n",
    "comparison_df[['model', 'system', 'type', 'extra_points', 'features']] = comparison_df['model_name'].str.split('_', expand=True, n=4)\n",
    "comparison_df = comparison_df.drop(columns=['system'])\n",
    "# Clean up the features column by removing \"_features\" if present\n",
    "comparison_df['features'] = comparison_df['features'].str.replace('_features', '')\n",
    "\n",
    "display(comparison_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "### Above 95%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "better_models = comparison_df[comparison_df['r2'] >= 0.95]\n",
    "better_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def viewGraph(filename, n):\n",
    "    system_load = SystemDesign.load(filename)\n",
    "\n",
    "    x,y = system_load.get_data_split_df()\n",
    "    y_pred = system_load.predict_model(x)\n",
    "\n",
    "    results_df = system_load.dataprocess.raw_data.merge(\n",
    "        y_pred,\n",
    "        left_index=True,\n",
    "        right_index=True,\n",
    "        suffixes=('','_pred')\n",
    "    )\n",
    "\n",
    "    group_index = int(results_df.iloc[n]['group_index'])\n",
    "    group = ja_groups[group_index]\n",
    "\n",
    "    ja_model = JouybanAcreeModel()  \n",
    "    x_values = np.linspace(0, 1, 101)\n",
    "\n",
    "    JA_fit_real = ja_model.predict(\n",
    "        x_values, \n",
    "        results_df['solvent_1_pure'].iloc[n],\n",
    "        results_df['solvent_2_pure'].iloc[n], \n",
    "        results_df['temperature'].iloc[n],\n",
    "        results_df['J0'].iloc[n],\n",
    "        results_df['J1'].iloc[n],\n",
    "        results_df['J2'].iloc[n],\n",
    "    )\n",
    "\n",
    "    JA_fit_NN = ja_model.predict(\n",
    "        x_values, \n",
    "        results_df['solvent_1_pure'].iloc[n],\n",
    "        results_df['solvent_2_pure'].iloc[n], \n",
    "        results_df['temperature'].iloc[n],\n",
    "        results_df['J0_pred'].iloc[n],\n",
    "        results_df['J1_pred'].iloc[n],\n",
    "        results_df['J2_pred'].iloc[n],\n",
    "    )\n",
    "\n",
    "    # Plot the JA model\n",
    "    plt.figure(figsize=(16*1.3/3, 9*1.3/3))\n",
    "    plt.plot(x_values, JA_fit_real, label='Empirical', color='blue')\n",
    "    plt.plot(x_values, JA_fit_NN, label='NN', color='red')\n",
    "\n",
    "\n",
    "    # Add the experimental data points to the plot\n",
    "    plt.scatter(group['solvent_1_weight_fraction'], group['solubility_g_g'], color='gray', label='Experimental Data')\n",
    "    plt.xlabel('Solvent 1 Weight Fraction')\n",
    "    plt.ylabel('Solubility (g/g)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group 377 for artunesate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewGraph(\"../../output/models/xgb_system_ss_0_10_features.pkl\",377)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
